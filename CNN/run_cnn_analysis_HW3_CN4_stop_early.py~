import numpy as np
import sys
import math
import time
import scipy.io as sio
from conv_mod import ArtistConvNet as AC
from six.moves import cPickle as pickle

def run_all_cnn_analysis():
  #Testing this shit
  print "Define Parameters"

  
  # Hyperparameters
  batch_size_array = [10]
  learning_rate_array = [0.01]
  layer1_filter_size_array = [5] 
  layer1_depth_array = [16]
  layer1_stride_array = [2] 
  layer2_filter_size_array = [5] 
  layer2_depth_array = [16]
  layer2_stride_array = [2] 
  layer3_num_hidden_array = [64] 
  layer4_num_hidden_array = [64] 
  num_training_steps_array = [1501] 
  
  # Add max pooling
  pooling_array = [False]
  layer1_pool_filter_size_array = [2]
  layer1_pool_stride_array = [2]
  layer2_pool_filter_size_array = [2]
  layer2_pool_stride_array = [2]

  # Enable dropout and weight decay normalization
  dropout_prob_array = [1.0] # set to < 1.0 to apply dropout, 1.0 to remove
  weight_penalty_array = [0.0] # set to > 0.0 to apply weight penalty, 0.0 to remove
  run_results_list = list()
  l_batch_size = list()
  l_learning_rate = list()
  l_layer1_depth = list()
  l_layer1_stride = list()
  l_layer2_filter_size = list()
  l_layer2_depth = list()
  l_layer1_filter_size = list()
  l_layer2_stride = list()
  l_layer3_num_hidden = list()
  l_layer4_num_hidden = list()
  l_num_training_steps = list()
  l_pooling = list()
  l_layer1_pool_filter_size = list()
  l_layer1_pool_stride = list()
  l_layer2_pool_filter_size = list()
  l_layer2_pool_stride = list()
  l_dropout_prob = list()
  l_weight_penalty = list()

  for batch_size in batch_size_array:
    for learning_rate in learning_rate_array:
      for layer1_filter_size in layer1_filter_size_array:
        for layer1_depth in layer1_depth_array:
          for layer1_stride in layer1_stride_array:
            for layer2_filter_size in layer2_filter_size_array:
              for layer2_depth in layer2_depth_array:
                for layer2_stride in layer2_stride_array:
                  for layer3_num_hidden in layer3_num_hidden_array:
                    for layer4_num_hidden in layer4_num_hidden_array:
                      for num_training_steps in num_training_steps_array:
                        for pooling in pooling_array:
                          for layer1_pool_filter_size in layer1_pool_filter_size_array:
                            for layer1_pool_stride in layer1_pool_stride_array:
                              for layer2_pool_filter_size in layer2_pool_filter_size_array:
                                for layer2_pool_stride in layer2_pool_stride_array:
                                  for dropout_prob in dropout_prob_array:
                                    for weight_penalty in weight_penalty_array:
                                      #print "Saving temp Parameters"
                                      pickle_file = 'temp_parm.pickle'
                                      save = {
                                        'batch_size': batch_size,
                                        'learning_rate': learning_rate,
                                        'layer1_depth': layer1_depth,
                                        'layer1_stride': layer1_stride,
                                        'layer2_filter_size': layer2_filter_size,
                                        'layer2_depth': layer2_depth,
                                        'layer1_filter_size': layer1_filter_size,
                                        'layer2_stride': layer2_stride,
                                        'layer3_num_hidden': layer3_num_hidden,
                                        'layer4_num_hidden': layer4_num_hidden,
                                        'num_training_steps': num_training_steps,
                                        'pooling': pooling,
                                        'layer1_pool_filter_size': layer1_pool_filter_size,
                                        'layer1_pool_stride': layer1_pool_stride,
                                        'layer2_pool_filter_size': layer2_pool_filter_size,
                                        'layer2_pool_stride': layer2_pool_stride,
                                        'dropout_prob': dropout_prob,
                                        'weight_penalty': weight_penalty
                                        }

                                      l_batch_size.append(batch_size)
                                      l_learning_rate.append(learning_rate)
                                      l_layer1_depth.append(layer1_depth)
                                      l_layer1_stride.append(layer1_stride)
                                      l_layer2_filter_size.append(layer2_filter_size)
                                      l_layer2_depth.append(layer2_depth)
                                      l_layer1_filter_size.append(layer1_filter_size)
                                      l_layer2_stride.append(layer2_stride)
                                      l_layer3_num_hidden.append(layer3_num_hidden)
                                      l_layer4_num_hidden.append(layer4_num_hidden)
                                      l_num_training_steps.append(num_training_steps)

                                      if pooling:
                                        l_pooling.append(1)
                                      else:
                                        l_pooling.append(0)

                                      l_layer1_pool_filter_size.append(layer1_pool_filter_size)
                                      l_layer1_pool_stride.append(layer1_pool_stride)
                                      l_layer2_pool_filter_size.append(layer2_pool_filter_size)
                                      l_layer2_pool_stride.append(layer2_pool_stride)
                                      l_dropout_prob.append(dropout_prob)
                                      l_weight_penalty.append(weight_penalty)

                                     # print pooling                                      
                                      save_pickle_file(pickle_file, save)
                                      #print "Save Successful Parameters"
                                      t1 = time.time()
                                      conv_net = AC(False,pickle_file)
                                      tmp = conv_net.train_model()

                                      run_results_list.append(tmp)
                                      t2 = time.time()
                                      print "Finished training. Total time taken:", t2-t1


  input_info = {
    'batch_size': l_batch_size,
    'learning_rate': l_learning_rate,
    'layer1_depth': l_layer1_depth,
    'layer1_stride': l_layer1_stride,
    'layer2_filter_size': l_layer2_filter_size,
    'layer2_depth': l_layer2_depth,
    'layer1_filter_size': l_layer1_filter_size,
    'layer2_stride': l_layer2_stride,
    'layer3_num_hidden': l_layer3_num_hidden,
    'layer4_num_hidden': l_layer4_num_hidden,
    'num_training_steps': l_num_training_steps,
    'pooling': l_pooling,
    'layer1_pool_filter_size': l_layer1_pool_filter_size,
    'layer1_pool_stride': l_layer1_pool_stride,
    'layer2_pool_filter_size': l_layer2_pool_filter_size,
    'layer2_pool_stride': l_layer2_pool_stride,
    'dropout_prob': l_dropout_prob,
    'weight_penalty': l_weight_penalty
    }                                      
  save_to_mat(run_results_list,input_info)

def save_to_mat(output_list,input_info):
  try:
    sio.savemat('cnn_stop_early_results.mat', {'results': output_list,'inputs': input_info})
  except Exception as e:
	  print('Unable to save list to mat:', e)
	  raise
def save_pickle_file(pickle_file, save_dict):
	try:
	  f = open(pickle_file, 'wb')
	  pickle.dump(save_dict, f, pickle.HIGHEST_PROTOCOL)
	  f.close()
	except Exception as e:
	  print('Unable to save data to', pickle_file, ':', e)
	  raise

	#print "Datasets saved to file", pickle_file


if __name__ == '__main__':
	run_all_cnn_analysis()
	print "Done"
